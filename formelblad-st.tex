% vim: foldmethod=marker spelllang=en

% Formelblad Stat based on Fredriks formelblad + Trans & Stat's formelblad:
% Version 0.1 IvTj, 2012-09-06: Converted to UTF-8
%         0.5 Lagt Exp,Bin, Wilcoxons 2012-09-13:
%         0.7 Tables isolated in Tables subdir, 2012-09-22:
%         0.9 Combined En-Swe version via \Tr{}{}
%         1.0 Spawned Tables in separate file
%         1.2 Ny upplägg, No joint distributions, mm, 2014-09-09
%         1.4 \xi -> X, \in -> \sim, bug i Stickprov i par:

\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{graphicx,amssymb}
\usepackage{array}   % nicer tables

% instead of \usepackage{fullpage} <<<
\advance \topmargin by -4.5\headheight
\advance \textheight by 25pt
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.6in
\parindent=0pt
\advance\parskip by 1pt
% >>>

\pagestyle{headings}
\everymath{\textstyle}
\def\obs{{\mbox{\tiny obs}}}
\def\CI{\mbox{CI}}
\def\Bin{\mbox{Bin}}
\def\Po{\mbox{Po}}
\def\Exp{\mbox{Exp}}

\input Lang.h % En-Sv settings outsourced

%% <<< Former \input\jobname.h ----------------

%-------------
%- LaTeX def's
%-------------

\everymath{\displaystyle}

\makeatletter
\renewcommand{\@oddhead}{}
\renewcommand{\@evenhead}{}
\renewcommand{\@oddfoot}
{\ifnum\thepage=1
  \today\hfill file:~\small\texttt{\jobname.pdf}
\else
\Tr{Cheat Sheet Mathematical Statistics}
   {Formelblad Matematisk Statistik}
  \hfill
  \Tr{p}{s}.~\thepage{} \Tr{of}{av} \pageref{LastPageNo}
\fi}

  \renewcommand{\@evenfoot}{\small
        \texttt{\jobname.pdf},\hfill}

\makeatother

%% restore good old TeX \eqalign:
\makeatletter

\def\eqalign#1{\null\,\vcenter{\openup\jot\m@th
  \ialign{\strut\hfil$\displaystyle{##}$&$\displaystyle{{}##}$\hfil
      \crcr#1\crcr}}\,}

\def\iint{\mathop{\relax\protect
    \noexpand\intop\mkern-9mu\noexpand\intop}\displaylimits}

\def\iiint{\mathop{\relax\protect
    \noexpand\intop\mkern-9mu\noexpand\intop\mkern-9mu\noexpand\intop}\displaylimits}


\makeatother


\newcommand\conj[1]{{\overline #1}}
\let\ob\conj
\newcommand\binom[2]{{#1\choose #2}}


% - sets -
\def\Rone{{\mathbb R}}
\def\Cone{{\mathbb C}}
\def\Zone{{\mathbb Z}}

% - operators -

\def\norm#1{{\Vert #1\Vert}}
\def\SP#1{\langle #1\rangle}
\def\Ordo{\mathcal O}
\def\Fourier#1{\mathcal F\left\{#1\right\}}
\def\Laplace#1{\mathcal L\left\{#1\right\}}
\def\invFourier#1{\mathcal F^{-1}\left\{#1\right\}}
\def\invLaplace#1{\mathcal L^{-1}\left\{#1\right\}}
\let\invFF\invFourier
\let\FF\Fourier
\let\invLL\invLaplace
\let\LL\Laplace

% - förkortnngar

\newcommand\mha{med hjälp av }
\newcommand\bis{^{\prime\prime}}
\newcommand\triss{^{'''}}
\newcommand\PartInt[2]{\left\lceil\matrix{\mbox{\small #1}\cr
                                       \mbox{\small #2}}\right\rceil}
\def\tfrac{\textstyle\frac}

%adjust row height in tables #1 - overall height #2 - depth:
\newcommand\TblHeight[2]{\lower#2em\vbox to#1em{\hsize=0pt}}
\def\tvavektor[#1,#2]{\protect\pmatrix{#1\cr #2}}
\def\trevektor[#1,#2,#3]{\protect\pmatrix{#1\cr #2\cr #3}}
\def\Var{\mbox{Var}}
\def\Cov{\mbox{Cov}}
\def\md{\mbox{md}}

%% End \input\jobname.h fold >>> -

\begin{document}


\section*{\Tr{Cheat Sheet Mathematical Statistics}{Matematisk Statistik, formelblad}}

\subsection*{\Tr{Probability laws}{Sannolikhetslära}}%<<<

%\textbf{\Tr{Notation}{Beteckningar}}:
   $A$, $B$, ... $\subset\Omega$ -- \Tr{events}{händelser},
   $\Omega$ -- \Tr{the sample space}{utfallsrummet},
   $A^c$ -- \Tr{the complement of}{komplementet till} $A$,
   $P(A)$ -- \Tr{the probability of event}{sannolikheten för} $A$:

%\textbf{\Tr{Properties}{Egenskaper}}:
\begin{itemize}\advance\itemsep by -5pt
  \item $0\le P(A)\le 1$, \/ $P(\Omega)=1$. \/
  \Tr{If}{Om}
  $A\cup B=\varnothing$,
    \Tr{then}{då}
  $P(A\cap B)=P(A)+P(B)$
  \item \Tr{If}{Om}
    $A_j\cap A_j=\varnothing$
    \Tr{for all}{för alla} $i\neq j$,
    \Tr{then}{då}
    $P(A_i\cup \ldots \cup A_n\cup \ldots)=P(A_1)+\cdots + P(A_n)+\cdots$
%  \item $P(A\cup B)\le P(A)+P(B)$, \Tr{equality if}{med likhet då} $A\cap B=\varnothing$
%   (\Tr{i.e., mutually exclusive}{dvs är disjunkta})
   \item $P(A^c) = 1-P(A)$ ($A^c$ \Tr{is the complement of}{är komplementet till} $A$)
  \item $P(A\cup B) = P(A)+P(B)-P(A\cap B)$.
  \item de Morgan:
    $P[(A\cup B)^c]=P(A^c\cap B^c)$,
    $P[(A\cap B)^c]=P(A^c\cup B^c)$.
\end{itemize}

\textbf{\Tr{Conditional probability}{Betingad sannolikhet}}:
$P(A|B) = \frac{P(A\cap B)}{P(B)}$

\textbf{\Tr{Independent events}{Oberoende händelser}}: $P(A\cap B) = P(A)P(B)$

\medskip
\textbf{Total \Tr{Probability Law}{sannolikhet}}:
  $P(B) = P(B|A)P(A) + P(B|A^c)P(A^c)$.
  \Tr{Generally, for events}{Allmännt, för händelserna}
\[
  \bigl\{A_k\bigr\}_{k=1}^n:
  \left\{
  \begin{array}{l}
  A_i\cap A_j = \varnothing, \; i\neq j, \\
  A_1\cup \dots\cup A_n=\Omega \\
  \end{array}
\right\}
  \;\rightsquigarrow\;
P(B) = \sum_{k=1}^n P(B\cap A_k)
     = \sum_{k=1}^n P(B|A_k) P(A_k)
\]

\textbf{\Tr{Bayes's theorem}{Bayes formula}}: $
P(A|B) = \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^c)P(A^c)}
$, $P(B) > 0$. \/
\Tr{Generally, for events}{Allmännt, för händelserna}
\[
  \bigl\{A_i\bigr\}_{i=1}^n:
  \left\{
  \begin{array}{l}
  A_i\cap A_j = \varnothing, \; i\neq j, \\
  A_1\cup \dots\cup A_n=\Omega \\
  \end{array}
\right\}
  \;\rightsquigarrow\;
P(A_j|B) = \frac{P(A_j\cap B)}{P(B)}
      = \frac{P(B|A_j) P(A_j)}
             {\sum_{k=1}^n P(B|A_k) P(A_k)}
 \]%>>>

\subsection*{\Tr{Expectation and Variance}{Väntevärde och varians}}%<<<

\textbf{\Tr{Expectation}{Väntevärde}}:
$
\Tr{
\mu=E(X)=\cases{
\sum_k x_kP(X=x_k), & $X$ -- discrete random variable\cr
\int_{-\infty}^\infty x f(x)\,dx , & $X$ -- continuous r.~v. with pdf $f$.
}
}{
\mu=E(X)=\cases{
\sum_k x_kP(X=x_k), & $X$ -- diskret stokastisk variabel\cr
\int_{-\infty}^\infty x f(x)\,dx , & $X$ -- kontinuerlig s.~v. med frekvensfunktion $f$.
}
}
$

\medskip
\textbf{\Tr{Variance}{Varians}}:
$
\sigma^2
=
\Tr{
\Var(X)=E[(x-\mu)^2]=\cases{
\sum_k (x_k-\mu)^2 P(X=x_k), & $X$ -- discrete random variable\cr
\int_{-\infty}^\infty (x-\mu)^2 f(x)\,dx , &  $X$ -- continuous r.~v. with pdf $f$.
}
}{
V(X)=E[(x-\mu)^2]=\cases{
\sum_k (x_k-\mu)^2 P(X=x_k), & $X$ -- diskret s.~v.\cr
\int_{-\infty}^\infty (x-\mu)^2 f(x)\,dx , & $X$ -- kontinuerlig s.~v.
}
}
$

\medskip
\textbf{\Tr{Standard deviation}{Standardavvikelse}}:
\Tr{ $\sigma=\sqrt{\Var(X)}$ } { $\sigma=\sqrt{V(X)}$ }
\hfil
\textbf{\Tr{Steiner's theorem}{Steiner's sats}}: $\sigma^2=E(X^2)-\mu^2$
%%% \Tr{
%%% \sigma^2=E(X^2)-\mu^2 %
%%% =\cases{
%%% \sum_k x_k^2 P(X=x_k)-\mu^2, & $X$ -- discrete random variable\cr
%%% \int_{-\infty}^\infty x^2 f(x)\,dx -\mu^2 , &  $X$ -- continuous r.~v. with pdf $f$.
%%% }
%%% }{
%%% \sigma^2=E(X^2)-\mu^2 %=E(X^2)-[E(X)]^2
%%% =\cases{
%%% \sum_k x_k^2 P(X=x_k)-\mu^2, & $X$ -- diskret s.~v.\cr
%%% \int_{-\infty}^\infty x^2 f(x)\,dx -\mu^2 , & $X$ -- kontinuerlig s.~v.
%%% }
%%% }
%>>>

\subsection*{\Tr{Linear combinations, sums and averages of random variables}%<<<
             {Linjära kombinationer, summor och snitt av stokastiska variabler}
         }
\Tr{%
Suppose that $\{X_k\}_{k=1}^n$ are (discrete or continuous) random variables with expectations
$E(X_k)=\mu_k$ and variances $\Var(X_k)=\sigma_k^2$, $k=1,...,n$, and let
 $\{a_k\}_{k=1}^n$ be constants. Then
}{%
Antag att $\{X_k\}_{k=1}^n$ är (diskreta eller kontinuerliga) stokastiska variabler med
väntevärden $E(X_k)=\mu_k$ och varianser $V(X_k)=\sigma_k^2$, $k=1,...,n$, samt
 $\{a_k\}_{k=1}^n$ är konstanter. Då gäller
}
\[
\Tr{
\eqalign{
E(a_1X_1+\cdots+a_nX_n)& =a_1\mu_1+\cdots + a_n\mu_n\cr
\Var(a_1X_1+\cdots+a_nX_n)& =a_1^2\sigma_1^2+\cdots + a_n^2\sigma_n^2
   \quad(\mbox{if $X_1,\ldots,X_n$ are independent}).
} % eqalign
}{
\eqalign{
   E(a_1X_1+\cdots+a_nX_n)& =a_1\mu_1+\cdots + a_n\mu_n\cr
V(a_1X_1+\cdots+a_nX_n)& =a_1^2\sigma_1^2+\cdots + a_n^2\sigma_n^2
   \quad(\mbox{om $X_1,\ldots,X_n$ är oberoende}).
} % eqalign
}
\]
\Tr{%
If $\{X_k\}_{k=1}^n$ are \textbf{normal and independent} r.\,v.,
then their linear combinations also are normally distributed:
}{%
Om $\{X_k\}_{k=1}^n$ är \textbf{normalfördelade och oberoende},
så är deras linjärkombinationer också normalfördelade:
}
\[
\Tr{X}{X}_k\Tr{\sim}{\sim} N(\mu_k,\sigma_k),\;
k=1,...,n
\;\Rightarrow\;
a_1\Tr{X}{X}_1+\cdots+a_n\Tr{X}{X}_n\Tr{\sim}{\sim} N\bigl(a_1\mu_1+\cdots a_n\mu_n,
                   \sqrt{a_1^2\sigma_1^2+\cdots a_n^2\sigma_n^2}\,\bigr).
\]
\Tr{%
For \textbf{sums} and \textbf{averages of i.d.~normal} variables, in particular, holds:
}{%
I synnerhet, för \textbf{summor} och \textbf{snitt av lika normalfördelade oberoende} variabler gäller:
}
$$
\Tr{X}{X}_k\Tr{\sim}{\sim} N(\mu,\sigma),\;
k=1,...,n
\;\Rightarrow\;
\cases{
\Tr{X}{X}_1+\cdots+\Tr{X}{X}_n \Tr{\sim}{\sim} N(n\mu,\sigma\sqrt{n})\cr\noalign{\vskip5pt}
\frac{\Tr{X}{X}_1+\cdots+\Tr{X}{X}_n}{n} = \Tr{\ob X}{\ob X} \Tr{\sim}{\sim} N(\mu,\frac{\sigma}{\sqrt{n}})
\Leftrightarrow
z:=\frac{\Tr{\ob X}{\ob X} -\mu}{\sigma/\sqrt{n}}\Tr{\sim}{\sim} N(0,1).
}
$$
%>>>

\subsection*{\Tr{The Central Limit Theorem (CLT)}{Centrala gränsvärdessatsen (CGS)}} %<<<

\Tr{%
Suppose that $X_1,\cdots, X_n$ are \textbf{independent identically distributed}  (i.i.d.)
random variables with expectation $\mu$ and standard deviation $\sigma$. Then for large $n$
holds:
}{%
Antag att $X_1,\cdots, X_n$ är \textbf{oberoende likafördelade} stokastiska
variabler med väntevärde $\mu$ och standardavvikelse $\sigma$. För stora $n$
gäller:
}

\begin{itemize}
  \item $S_n=\sum_{k=1}^n \Tr{X}{X}_k=\Tr{X}{X}_1+\cdots+\Tr{X}{X}_n\;
    \stackrel{\mbox{\tiny appr}}{\sim}\; N(n\mu,\sigma\sqrt{n})$,
        \ \Tr{i.e.}{dvs}, \,
        $P(S_n\le x)\approx
        \Phi(z),\, z=\frac{x-n\mu}{\sigma\sqrt{n}}
        $;

      \item $\Tr{\ob X}{\ob X}=\frac{S_n}n
    =\frac{\Tr{X}{X}_1+\cdots+\Tr{X}{X}_n}n\;
    \stackrel{\mbox{\tiny appr}}{\sim}\; N(\mu,\frac\sigma{\sqrt{n}})$,
        \ \Tr{i.e.}{dvs}, \,
        $P(\Tr{\ob X}{\ob X}\le \ob x)\approx\Phi(z)$, \,
        $z=\frac{\ob x-\mu}{\sigma/\sqrt{n}}\cdot$
\end{itemize}
%>>>

\subsection*{\Tr{Approximations of distributions}{Approximationer}}%<<<
\medskip
\begin{center}
   \includegraphics[scale=0.65]{Figs/approx}
\end{center}
%>>>

\subsection*{\Tr{Parameters of some distributions}%<<<
             {Några ofta förekommande fördelningar}}

\def\EspaceAuDessus{&&&&\\*[-10pt]}\def\duPlancher{\\*[2pt] \hline}

\begin{tabular}{|c|c|c|c|c|}
\cline{1-2}
\multicolumn{2}{ |l| }{\textbf{\Tr{Discrete distributions}{Diskreta fördelningar}} ($x=0,1,2,\ldots$):} \cr
\hline
\EspaceAuDessus     \Tr{$X$ from}{$X$ från}
                  & $f(x)=P(X=x)$
                  & \Tr{$F(x)=P(X\le x)$}{$F(x)=P(X\le x)$}
                  & \Tr{$\mu=E(X)$}{$\mu=E(X)$}
                  & \Tr{$\sigma=\sqrt{\Var(X)}$}{$\sigma=\sqrt{V(X)}$}
                  \duPlancher
\hline
\EspaceAuDessus $\mbox{Unif}\{1,n\}$  &
                  $ \frac{1}{n},\; 1\le\! x\le\! n $ &
                  $ \frac{x}{n},\; 1\le\! x\le\! n $ &
                  $\frac{n+1}{2}$ &
                  $\frac{\sqrt{n^2-1}}{2\sqrt{3}}$
                  \cr &&&&\\[-23pt]
                  \duPlancher
  \EspaceAuDessus $\mbox{Geo}(p)$,\, $x\ge1$ &
                  $p(1-p)^{x-1}$ &
                  $1 - (1-p)^x$ &
                  $1/p$ & $\sqrt{1-p}\big/p$\duPlancher
  \EspaceAuDessus $\mbox{Hyp}(N,n,p)$ &
                  $\frac{\binom{Np}x\binom{N(1-p)}{n-x}}{\binom{N}{n}}$ &
                  $\sum_{k=0}^x\frac{\binom{Np}k\binom{N(1-p)}{n-k}}{\binom{N}{n}}$ &
                  $np$ & $\sqrt{\tfrac{N-n}{N-1}\,np(1-p)}$\duPlancher
  \EspaceAuDessus $\mbox{Bin}\,(n,p)$    &
                  $\binom nx p^x(1-p)^{n-x}$ &
                  $\sum_{k=0}^x\binom nk p^k(1-p)^{n-k}$ &
                  $np$ & $\sqrt{np(1-p)}$\duPlancher
  \EspaceAuDessus $\Po(\mu) $ &
                  $e^{-\mu}\,\frac{\mu^x}{x!}$ &
                  $e^{-\mu}\,\sum_{k=0}^x \frac{\mu^k}{k!}$ &
                  $\mu$ & $\sqrt{\mu}$\duPlancher
\end{tabular}

\medskip
\begin{tabular}{|c|c|c|c|c|}
\cline{1-2}
\multicolumn{2}{ |l| }{\textbf{\Tr{Continuous distributions}{Kontinuerliga fördelningar}}:} \cr
\hline
\EspaceAuDessus     \Tr{$X$ from}{$X$ från}
                  & $f(x)$
                  & \Tr{$F(x)=P(X\le x)$}{$F(x)=P(X\le x)$}
                  & \Tr{$\mu=E(X)$}{$\mu=E(X)$}
                  & \Tr{$\sigma=\sqrt{\Var(X)}$}{$\sigma=\sqrt{V(X)}$}
                  \duPlancher
\hline
  \EspaceAuDessus $\mbox{Unif}(a,b)$  &
                  $ \frac{1}{b-a},\; a\le\! x\le\! b $ &
                  $\frac{x-a}{b-a},\; a\le\! x\le\! b $ &
                  $\frac{a+b}{2}$ &
                  $\frac{b-a}{2\sqrt{3}}$
                  \cr &&&&\\[-23pt]
                  \duPlancher
  \EspaceAuDessus $\mbox{Exp}(\lambda)$  &
                  $\lambda e^{-\lambda x}$,\, $x\ge0$ &
                  $1-e^{-\lambda x}$ &
                  $1/\lambda$ & $1/\lambda$\duPlancher
  \EspaceAuDessus $N(\mu,\sigma) $ &
                  %% $\frac{1}{\sigma\sqrt{2\pi}}\,e^{-(x-\mu)^2/2\sigma^2}$ &
                  $\frac{1}{\sigma\sqrt{2\pi}}\,e^{-(\frac{x-\mu}\sigma)^2/2}$ &
                  $\Phi\Bigl(\frac{x-\mu}{\sigma}\Bigr)
                  =\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\frac{x-\mu}{\sigma}} e^{-t^2/2}\,dt$ &
                  $\mu$ & $\sigma$\\*[10pt]\hline
\end{tabular}

\medskip
\textbf{\Tr{A Poisson process of intensity}{Poissonprocess med intensitet}} $\lambda$:

\Tr{A point process where times between consecutive points are i.i.d.~random variables that are $\Exp(\lambda)$}
   {Fullständig slumpmässig följd av händelser i tiden, antal punkter $\Po(\lambda t)$, tid mellan punkter: $\Exp(\lambda)$}.
%>>>

\subsection*{\Tr{Statistical inference}{Statistisk inferens}}%<<<

\Tr{%
\textbf{Point estimators}:
Let $x_1,\dots,x_n$ be the observed values of a sample $\left\{X_k\right\}_1^n$ from a population with
mean $\mu$ och standard deviation $\sigma$. Point estimators
for the mean and the variance of the population are
}{%
\textbf{Punktskattningar}:
Låt $x_1,\dots,x_n$ vara de observerade värden för ett stickprov
$\left\{X_k\right\}_1^n$ från en population med
väntevärde $\mu$ och standardavvikelse $\sigma.$ Väntevärdesriktiga skattningar
av $\mu$ och $\sigma^2$ är då
}

\Tr{%
\begin{itemize}
  \item % $\hat\mu = \ob X = \frac1n\sum_{k=1}^{n}X_k$, computed from the observed values as
    $\overline{x}=\frac{1}{n}\sum_{k=1}^n x_k$

 \item $\displaystyle
     %\left(\sigma^2_\obs\right)^*=
     s^2
     =\frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})^2
     =\frac{1}{n-1}\left(\sum_{i=1}^nx_i^2-n\overline{x}^2\right)\;\;\;$
     (if the mean is not known).
\end{itemize}
}{%
\begin{itemize}
  \item $\displaystyle \mu^*_\obs=\overline{x}=\frac{1}{n}\sum_{i=1}^n x_i$

 \item $\displaystyle
     \left(\sigma^2_\obs\right)^*
     =s^2
     =\frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})^2
     =\frac{1}{n-1}\left(\sum_{i=1}^nx_i^2-n\overline{x}^2\right)\;\;\;$
     (då $\mu$ ej känd).
\end{itemize}
}%>>>

\subsection*{\Tr{Confidence Interval -- One Sample}{Konfidensintervall - ett stickprov}}%<<<

\begin{eqnarray*}\begin{array}{|ccc|}\hline
     \mbox{\Tr{Estimated paramter $\theta$}{Parameter $\theta$ som skattas}}
   & \mbox{\Tr{Point estimate}{Punktskattning}}
   & \mbox{\Tr{Two-tailed}{Tvåsidigt konfidensintervall} }
   \CI_{1-\alpha}(\theta) \\

\hline && \\
\mu \;\mbox{\Tr{from}{från} } N(\mu,\sigma),\; \sigma \mbox{ \Tr{known}{känd}}
 & \overline{x}
 &  [\ob x-\varepsilon,\ob x+\varepsilon],\;
    \varepsilon = \Tr{z}{\lambda}_{\alpha/2}\frac{\sigma}{\sqrt{n}}\\&&\\

\hline &&\\
\mu \;\mbox{\Tr{from}{från} } N(\mu,\sigma),\; \sigma \mbox{ \Tr{not known}{ej känd}}
 & \overline{x}
& [\ob x-\varepsilon,\ob x+\varepsilon],\;  \varepsilon = t_{\alpha/2,n-1}\frac{s}{\sqrt{n}}\\&&\\

\hline &&\\
\sigma^2 \;\mbox{\Tr{from}{från} } N(\mu,\sigma)
 & s^2&\frac{(n-1)s^2}{\chi^2_{\alpha/2,n-1}}
  \leq\sigma^2
  \leq \frac{(n-1)s^2}{\chi^2_{1-\alpha/2,n-1}}

\\&&\\

\hline &&\\p \;\mbox{ \Tr{from}{från} Bin}(n,p) & \Tr{\hat p=\frac x n}{p^*_\obs}
& [
  \Tr{\hat p}{p^*_\obs}-\varepsilon ,
  \Tr{\hat p}{p^*_\obs}+\varepsilon ],\;
 \varepsilon =
 \Tr{z}{\lambda}_{\alpha/2}\sqrt{\frac{\Tr{\hat p}{p^*_\obs}(1-\Tr{\hat p}{p^*_\obs})}{n}}

 \\&&\\
\hline

  \end{array}
\end{eqnarray*}
%>>>

\subsection*{\Tr{Confidence Interval for the Mean -- Two Samples}%<<<
                   {Konfidensintervall -- två normalfördelade stickprov}}

\begin{itemize}

\item \textbf{\Tr{Two samples (paired data)}{Två parade stickprov}}: %<<<
  $\{(X_i,Y_i)\}_{i=1}^n$
  \Tr{with}{där}
   $X_i\Tr{\sim}{\sim} N(\mu_i,\sigma_x)$ \Tr{and}{och}
   $Y_i\Tr{\sim}{\sim} N(\mu_i+\Delta,\sigma_y)$, $i=1,\dots,n$.
   \Tr{Then}{Då} $\{Z_i\}_1^n=\{Y_i-X_i\}_1^n$
   \Tr{is a sample from}{är ett stickprov från}
   $N(\Delta,\sigma_z)$.
  % \Tr{with}{där} $\sigma_z=\sqrt{\sigma_x^2+\sigma_y^2}$\,. <- Lögn, kan vara korrelerade!
   \Tr{The two-sided $\CI_{1-\alpha}$ for}{Det tvåsidiga $\CI_{1-\alpha}$ för} $\Delta$:

\[
\CI_{1-\alpha}(\Delta) = [\ob z-\varepsilon,\ob z+\varepsilon],\quad
   \varepsilon =
   \cases{
      \Tr{z}{\lambda}_{\alpha/2}\,\frac{\sigma_z}{\sqrt{n}}\;,
          & \Tr{if}{om} $\sigma_z$ \Tr{is known}{är känd} \cr
      t_{\alpha/2,n-1}\,\frac{s_z}{\sqrt{n}}\;,
      & \Tr{if}{om} $\sigma_z$ \Tr{is not known}{är ej känd} \cr
   }
\]%>>>

\item \textbf{\Tr{Two independent samples (pooled test)}{Två oberoende stickprov}}:
$\{X_i\}_{i=1}^{n}$ \Tr{from}{från} $N(\mu_x,\sigma)$
  \Tr{and}{och}
  $\{Y_i\}_{i=1}^{m}$ \Tr{from}{från} $N(\mu_y,\sigma)$.
  \Tr{The two-tailed $\CI_{1-\alpha}$ for $\mu_x-\mu_y$ is given by}
      {Det tvåsidiga $\CI_{1-\alpha}$ för $\mu_x-\mu_y$ ges av}
\[
\CI_{1-\alpha}(\mu_x-\mu_y) = [(\ob x-\ob y)-\varepsilon,(\ob x-\ob y)+\varepsilon],\quad
   \varepsilon =
   \cases{
   \Tr{z}{\lambda}_{\alpha/2}\,\sigma\sqrt{\frac1n+\frac1m},
          & \Tr{if}{om} $\sigma$ \Tr{is known}{är känd} \cr
          t_{\alpha/2,n+m-2}\,\Tr{s_p}{\sigma^*_\obs}\sqrt{\frac1n+\frac1m}\,,
      & \Tr{if}{om} $\sigma$ \Tr{is not known}{är ej känd}, \cr
   }
\]
\Tr{where}{där}
$\Tr{s_p}{\sigma^*_\obs}$
\Tr{is the pooled (weighted) standard deviation}{är den vägda standardavvikelsen}
\/$ \Tr{s_p}{\sigma^*_\obs} =\sqrt{\frac{(n-1)s_x^2+(m-1)s_y^2}{n+m-2}}\,\cdot$

\end{itemize}
%>>>

\subsection*{\Tr{Hypothesis tests}{Hypotestest}}%<<<

\subsubsection*{ \Tr{Parametric methods}{Parametriska metoder}}%<<<

\begin{eqnarray*}\begin{array}{|cccc|}
  \hline
   \mbox{\Tr{Null hypothesis}{Nollhypotes}} &
   \mbox{\Tr{Test variable}{Testvariabel}} &
   \mbox{\Tr{Alt.~hypothesis}{Mothypotes}}  &
   \mbox{\Tr{$H_0$ rejected if}{När $H_0$ förkastas}}
  \\ \hline &&&\\[-10pt]
  &&H_1:\mu\neq\mu_0&\vert z_0\vert>\Tr{z}{\lambda}_{\alpha/2} \\
    H_0:\mu=\mu_0
   &z_0=\frac{\overline{x}-\mu_0}{\sigma/\sqrt{n}}
   &H_1:\mu>\mu_0&z_0>\Tr{z}{\lambda}_\alpha\\
   \sigma \mbox{ \Tr{known}{känd}}
  &&H_1:\mu<\mu_0&z_0<-\Tr{z}{\lambda}_\alpha
  \\ \hline &&&\\[-10pt]
  &&H_1:\mu\neq\mu_0&\vert t_0\vert>t_{\alpha/2,n-1} \\
    H_0:\mu=\mu_0 & t_0=\frac{\overline{x}-\mu_0}{s/\sqrt{n}}
   &H_1:\mu>\mu_0 & t_0>t_{\alpha,n-1}  \\
   \sigma \mbox{ \Tr{not known}{ej känd}}
  &&H_1:\mu<\mu_0 & t_0<-t_{\alpha,n-1}
\\ \hline &&&\\[-10pt]
  &&H_1:\sigma^2\neq\sigma^2_0
    % & \chi^2_0<\chi^2_{1-\alpha/2,n-1} \mbox{\, \Tr{or}{eller} \,\,} \chi^2_0>\chi^2_{\alpha/2,n-1}
    & \chi^2_0 \notin [\chi^2_{1-\alpha/2,n-1} \,,\, \chi^2_{\alpha/2,n-1}]
     \\
 H_0:\sigma^2=\sigma^2_0
    &\chi^2_0=\frac{(n-1)s^2}{\sigma^2_0}
    &H_1:\sigma^2>\sigma^2_0
    &\chi^2_0>\chi^2_{\alpha,n-1}  \\
&&H_1:\sigma^2<\sigma^2_0&\chi^2_0<\chi^2_{1-\alpha,n-1}
\\ \hline &&&\\[-10pt]
  &&H_1:p\neq p_0&\vert z_0\vert>\Tr{z}{\lambda}_{\alpha/2}\\
   H_0:p=p_0
   &z_0=\frac{x-np_0}{\sqrt{np_0(1-p_0)}}
   &H_1:p>p_0&z_0>\Tr{z}{\lambda}_\alpha \\
  &&H_1:p<p_0&z_0<-\Tr{z}{\lambda}_\alpha
\\ \hline \end{array}
\end{eqnarray*}
%>>>

\subsubsection*{\Tr{Non-parametric methods}{Icke-parametriska metoder}}%<<<

\vspace{-5pt}
\begin{center}
\begin{tabular}[t]{|c|*{4}{>{$}c<{$}}|}
  \cline{2-5}\multicolumn{1}{c|}{}
   &
   \mbox{\Tr{Null hypothesis}{Nollhypotes}} &
   \mbox{\Tr{Alt.~hypothesis}{Mothypotes}}  &
   \mbox{\Tr{Test variable}{Testvariabel}} &
   \mbox{\Tr{$H_0$ rejected if}{När $H_0$ förkastas}}
   \\ \hline
     &&H_1:{\md}\neq{\md}_0&r=\min(r^-,r^+)&r\leq r_{\alpha/2} \\
     \mbox{\textbf{\Tr{Sign test}{Teckentest}}}
      &H_0:{\md}={\md}_0&H_1:{\md}>{\md}_0&r^-&r^-\leq r_\alpha \\
     \mbox{\Tr{for the median}{för medianen}}
     &&H_1:{\md}<{\md}_0&r^+&r^+\leq r_\alpha
 \\\hline
\end{tabular}

\vspace{5pt}
\begin{tabular}[t]{|c|*{3}{>{$}c<{$}}|}
  \cline{2-4}\multicolumn{1}{c|}{}
   &
   \mbox{\Tr{Null hypothesis}{Nollhypotes}} &
   \mbox{\Tr{Alt.~hypothesis}{Mothypotes}}  &
   \mbox{\Tr{$H_0$ rejected if}{När $H_0$ förkastas}}
   \\ \hline
   \mbox{\textbf{Wilcoxon\Tr{'}{}s}}
 %%% Fredrik's old %<<<
 %%%           &&H_A:\mu_A\neq\mu_B&w=\min(w_A,w_B)&w\leq w^*_\alpha\\
 %%% \mbox{\Tr{Rang Sum Test}{Rangsummatest}}
 %%%            &H_0:\mu_A=\mu_B&H_A:\mu_A>\mu_B&w_B&w_B\leq w^*_\alpha \\
 %%% \mbox{\Tr{Requires}{Krav}: }n_A\leq n_B
 %%%           &&H_A:\mu_A<\mu_B&w_A&w_A\leq w^*_\alpha \\\hline
 %%% %>>>
            &&H_1:\mu_A\neq\mu_B
            &(w_A \leq w^-_{\alpha/2}) \mbox{ or }
             (w_A \geq w^+_{\alpha/2})
             \cr
\textbf{\Tr{Rank Sum Test}{Rangsummatest}}
             &H_0:\mu_A=\mu_B&H_1:\mu_A>\mu_B&w_A\geq w^+_\alpha \\
  \Tr{Requires}{Krav}: $n_A\leq n_B$
            &&H_1:\mu_A<\mu_B&w_A\leq w^-_\alpha \\\hline
\end{tabular}
\end{center}
%>>>

\subsubsection*{Test statistic for the $\chi^2$-tests:}%<<<

\vspace{-5pt}
\hfil
\begin{tabular}[t]{|c|c|}
  \hline
  \textbf{Goodness-of-fit}:
     $\chi^2 = \sum_{i=1}^{n}\frac{(O_i-E_i)^2}{E_i}$ &
     \parbox[m]{12em}{
     \textbf{Test for independence}: \\
    ($m\times n$-contingency table)
     }
  $\chi^2 = \sum_{i=1}^m\sum_{j=1}^{n}\frac{(O_{ij}-E_{ij})^2}{E_{ij}}$ \cr
  \hline
\end{tabular}
%>>>

%>>>

\label{LastPageNo}
\end{document}

>> THROWNAWAY SECTION:

\section*{Joint distributions}%<<<

\begin{itemize}

  \item \textbf{Joint density, discrete case}: %<<<
$
f_{XY}(x,y) = P[(X = x)\cap(Y = y)],
\quad
\cases{
  f_{XY}(x,y)\ge 0
  \cr
  \sum_x
  \sum_y
  f_{XY}(x,y) = 1.
}
$%>>>

  \item \textbf{The joint density in the continuous case} is a function $f_{X,Y}(x,y)\ge 0$ which satisfies: %<<<
\[
P[(a\le X\le b)\cap(c\le Y\le d)] =
 \int\limits_a^b\mkern-10mu\int\limits_c^d f_{XY}(x,y) \,dxdy,
\qquad
\iint_{\mkern-12mu\Rone^2} f_{XY}\,dxdy = 1.
\]

  \item \textbf{Cumulative distribution function} (discrete and continuous):
  $F_{XY}(x,y)=P[(X\le x)\cap(Y\le y)]$.%>>>

  \item \textbf{Marginal densities}: %<<<
    \[
      F_X(x) = \cases{
      \sum_y f_{XY}(x,y) &, discrete case
         \cr
         \int_{-\infty}^\infty f_{XY}(x,y)\,dy &, continuous case
      }
      \quad
      F_Y(y) = \cases{
      \sum_x f_{XY}(x,y) &, discrete case
         \cr
      \int_{-\infty}^\infty f_{XY}(x,y)\,dx &, continuous case.
      }
    \]%>>>

  \item Variables $X$ and $Y$ are \textbf{independent} if: %<<<
  $f_{XY}(x,y)=f_X(x)f_Y(y)$.%>>>

  \item \textbf{Expectations}:%<<<
    \[
\eqalign{
\mu_x
 & = E(X) = \cases{
    \sum_x\sum_y xf_{XY}(x,y) = \sum_x xf_X(x) &, discrete case \cr
    \iint_{\mkern-12mu\Rone^2}xf_{XY}(x,y)\,dxdy = \int_{-\infty}^\infty xf_{X}(x)\,dx &, continuous case
    }
\cr
\mu_y
  & = E(Y) = \cases{
    \sum_x\sum_y yf_{XY}(x,y) =\sum_y yf_X(y) &, discrete case \cr
    \iint_{\mkern-12mu\Rone^2}yf_{XY}(x,y)\,dxdy = \int_{-\infty}^\infty yf_{Y}(y)\,dy &, continuous case.
    }
   }
\]%>>>

  \item \textbf{Covariance}: %<<<
  \[
  \Cov(X,Y) = E[(X-\mu_x)(Y-\mu_y)]= E(XY)-\mu_x\mu_y .
%%  \mbox{ In particular, }\Var(X)=\Cov(X,X).
  \] %>>>

  \item \textbf{Pearson coefficient of correlation}:%<<<
  \[
  \rho_{XY} = \frac{\Cov(X,Y)}{\sigma_X\sigma_Y}
       = \frac{\Cov(X,Y)}{\sqrt{\Cov(X,X)\Cov(Y,Y)}}\, ,
       \quad
       -1\le\rho\le 1.
  \]%>>>

\item If the random variables $X$ and $Y$ are \textbf{independent}
    $\Rightarrow$ $\rho_{XY}=0$ ($X$ and $Y$ are
    \textbf{uncorrelated}). The converse is not true in general.

\end{itemize} %>>>
