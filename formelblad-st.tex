% vim: foldmethod=marker spelllang=en

% Formelblad Stat based on Fredriks formelblad + Trans & Stat's formelblad:
% Version 0.1 IvTj, 2012-09-06: Converted to UTF-8
%         0.5 Lagt Exp,Bin, Wilcoxons 2012-09-13:
%         0.7 Tables isolated in Tables subdir, 2012-09-22:
%         0.9 Combined En-Swe version via \Tr{}{}
%         1.0 Spawned Tables in separate file
%         1.2 Ny upplägg, No joint distributions, mm, 2014-09-09
%         1.4 \xi -> X, \in -> \sim, bug i Stickprov i par:

\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{graphicx,amssymb}
\usepackage{array}   % nicer tables

% instead of \usepackage{fullpage} <<<
\advance \topmargin by -4.5\headheight
\advance \textheight by 25pt
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.6in
\parindent=0pt
\advance\parskip by 1pt
\advance\textheight by 50 pt
% >>>

\pagestyle{headings}
\everymath{\textstyle}
\def\obs{{\mbox{\tiny obs}}}
\def\CI{\mbox{CI}}
\def\Bin{\mbox{Bin}}
\def\Po{\mbox{Po}}
\def\Exp{\mbox{Exp}}

\input Lang.h % En-Sv settings outsourced

%% <<< Former \input\jobname.h ----------------

%-------------
%- LaTeX def's
%-------------

\everymath{\displaystyle}

\makeatletter
\renewcommand{\@oddhead}{}
\renewcommand{\@evenhead}{}
\renewcommand{\@oddfoot}
{\ifnum\thepage=1
  \today\hfill file:~\small\texttt{\jobname.pdf}
\else
\Tr{Cheat Sheet Mathematical Statistics}
   {Formelblad Matematisk Statistik}
  \hfill
  \Tr{p}{s}.~\thepage{} \Tr{of}{av} \pageref{LastPageNo}
\fi}

  \renewcommand{\@evenfoot}{\small
        \texttt{\jobname.pdf},\hfill}

\makeatother

%% restore good old TeX \eqalign:
\makeatletter

\def\eqalign#1{\null\,\vcenter{\openup\jot\m@th
  \ialign{\strut\hfil$\displaystyle{##}$&$\displaystyle{{}##}$\hfil
      \crcr#1\crcr}}\,}

\def\iint{\mathop{\relax\protect
    \noexpand\intop\mkern-9mu\noexpand\intop}\displaylimits}

\def\iiint{\mathop{\relax\protect
    \noexpand\intop\mkern-9mu\noexpand\intop\mkern-9mu\noexpand\intop}\displaylimits}


\makeatother


\newcommand\conj[1]{{\overline #1}}
\let\ob\conj
\newcommand\binom[2]{{#1\choose #2}}


% - sets -
\def\Rone{{\mathbb R}}
\def\Cone{{\mathbb C}}
\def\Zone{{\mathbb Z}}

% - operators -

\def\norm#1{{\Vert #1\Vert}}
\def\SP#1{\langle #1\rangle}
\def\Ordo{\mathcal O}
\def\Fourier#1{\mathcal F\left\{#1\right\}}
\def\Laplace#1{\mathcal L\left\{#1\right\}}
\def\invFourier#1{\mathcal F^{-1}\left\{#1\right\}}
\def\invLaplace#1{\mathcal L^{-1}\left\{#1\right\}}
\let\invFF\invFourier
\let\FF\Fourier
\let\invLL\invLaplace
\let\LL\Laplace

% - förkortnngar

\newcommand\mha{med hjälp av }
\newcommand\bis{^{\prime\prime}}
\newcommand\triss{^{'''}}
\newcommand\PartInt[2]{\left\lceil\matrix{\mbox{\small #1}\cr
                                       \mbox{\small #2}}\right\rceil}
\def\tfrac{\textstyle\frac}

%adjust row height in tables #1 - overall height #2 - depth:
\newcommand\TblHeight[2]{\lower#2em\vbox to#1em{\hsize=0pt}}
\def\tvavektor[#1,#2]{\protect\pmatrix{#1\cr #2}}
\def\trevektor[#1,#2,#3]{\protect\pmatrix{#1\cr #2\cr #3}}
\def\Var{\mbox{Var}}
\def\Cov{\mbox{Cov}}
\def\md{\mbox{md}}

%% End \input\jobname.h fold >>> -

\begin{document}

\section*{\Tr{Cheat Sheet Mathematical Statistics}{Matematisk Statistik, formelblad}}%<<<

\subsection*{\Tr{Some notable sums and series}{Några summor och serier}}
\[
  \sum_{k=0}^{n}z^k = 1 + z + z^2 + \cdots +z^n = \frac{1-z^{n+1}}{1-z},\; z \neq 1;
  \hspace{3em}\sum_{k=0}^{\infty}z^k = \frac{1}{1-z},\; |z| < 1;
  \hspace{3em}\sum_{k=0}^{\infty}\frac{z^k}{k!} = e^z
\]%>>>

\subsection*{\Tr{Probability laws}{Sannolikhetslära}}%<<<

%\textbf{\Tr{Notation}{Beteckningar}}:
   $A$, $B$, ... $\subset\Omega$ -- \Tr{events}{händelser},
   $\Omega$ -- \Tr{the sample space}{utfallsrummet},
   $A^c$ -- \Tr{the complement of}{komplementet till} $A$,
   $P(A)$ -- \Tr{the probability of event}{sannolikheten för} $A$:

%\textbf{\Tr{Properties}{Egenskaper}}:
\begin{itemize}\advance\itemsep by -5pt
  \item $0\le P(A)\le 1$, \/ $P(\Omega)=1$. \/
  \Tr{If}{Om}
  $A\cap B=\varnothing$,
    \Tr{then}{då}
  $P(A\cup B)=P(A)+P(B)$
  \item \Tr{If}{Om}
    $A_j\cap A_j=\varnothing$
    \Tr{for all}{för alla} $i\neq j$,
    \Tr{then}{då}
    $P(A_i\cup \ldots \cup A_n\cup \ldots)=P(A_1)+\cdots + P(A_n)+\cdots$
%  \item $P(A\cup B)\le P(A)+P(B)$, \Tr{equality if}{med likhet då} $A\cap B=\varnothing$
%   (\Tr{i.e., mutually exclusive}{dvs är disjunkta})
   \item $P(A^c) = 1-P(A)$ ($A^c$ \Tr{is the complement of}{är komplementet till} $A$)
  \item $P(A\cup B) = P(A)+P(B)-P(A\cap B)$.
  \item de Morgan:
    $P[(A\cup B)^c]=P(A^c\cap B^c)$,
    $P[(A\cap B)^c]=P(A^c\cup B^c)$.
\end{itemize}

\textbf{\Tr{Conditional probability}{Betingad sannolikhet}}:
$P(A|B) = \frac{P(A\cap B)}{P(B)}$

\textbf{\Tr{Independent events}{Oberoende händelser}}: $P(A\cap B) = P(A)P(B)$

\medskip
\textbf{Total \Tr{Probability Law}{sannolikhet}}:
  $P(B) = P(B|A)P(A) + P(B|A^c)P(A^c)$.
  \Tr{Generally, for events}{Allmänt, för händelserna}
\[
  \bigl\{A_k\bigr\}_{k=1}^n:
  \left\{
  \begin{array}{l}
  A_i\cap A_j = \varnothing, \; i\neq j, \\
  A_1\cup \dots\cup A_n=\Omega \\
  \end{array}
\right\}
  \;\rightsquigarrow\;
P(B) = \sum_{k=1}^n P(B\cap A_k)
     = \sum_{k=1}^n P(B|A_k) P(A_k)
\]

\textbf{\Tr{Bayes's theorem}{Bayes formula}}: $
P(A|B) = \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^c)P(A^c)}
$, $P(B) > 0$. \/
\Tr{Generally, for events}{Allmänt, för händelserna}
\[
  \bigl\{A_i\bigr\}_{i=1}^n:
  \left\{
  \begin{array}{l}
  A_i\cap A_j = \varnothing, \; i\neq j, \\
  A_1\cup \dots\cup A_n=\Omega \\
  \end{array}
\right\}
  \;\rightsquigarrow\;
P(A_j|B) = \frac{P(A_j\cap B)}{P(B)}
      = \frac{P(B|A_j) P(A_j)}
             {\sum_{k=1}^n P(B|A_k) P(A_k)}
 \]%>>>

\subsection*{\Tr{Expectation and Variance}{Väntevärde och varians}}%<<<

\(
\begin{array}[m]{|l|l|l|}
\hline
\rule{0pt}{11pt}
\mbox{\textbf{\Tr{Expectation}{Väntevärde}}}
& \mbox{\textbf{\Tr{Of a random variable}{av en stokastisk variabel} }} X
& \mbox{\textbf{\Tr{Of a function of a r.v}{av en funktion av en s.v.} }} g(X) \cr 
  \hline
  \rule{0pt}{15pt}
  \mbox{\textbf{\Tr{Discrete r.v.}{Diskret s.v.} }}
  & \mu=E(X) = \sum_k x_kP(X=x_k)
  &  E[g(X)] = \sum_k g(x_k)P(X=x_k)  \\[10pt]
  \hline
  \rule{0pt}{18pt}
  \mbox{\textbf{\Tr{Continuous r.v.~of}{Kontinuerlig s.v.~med} pdf }} f(x)
  & \mu=E(X) = \int_{-\infty}^\infty x f(x)\,dx
  & E[g(X)] = \int_{-\infty}^\infty g(x) f(x)\,dx \\[10pt]
  \hline
\end{array}
\)

\medskip
\(
\begin{array}[m]{|l|l|l|}
\hline
\rule{0pt}{11pt}
\mbox{\textbf{\Tr{Variance}{Varians}}}
  & \mbox{\textbf{\Tr{Standard deviation}{Standardavvikelse}}}
  & \mbox{\textbf{\Tr{Steiner's theorem}{Steiner's sats}}} \cr
  \hline
  \rule{0pt}{13pt}
  \sigma^2 = \Var(X) = E[(X-\mu)^2]
  & \sigma = \sqrt{\Var(X)}
  & \sigma^2=E(X^2)-\mu^2 \cr
  \hline
\end{array}
\)
%>>>

\subsection*{\Tr{Parameters of some distributions}%<<<
             {Några ofta förekommande fördelningar}}

\def\EspaceAuDessus{&&&&\\*[-10pt]}\def\duPlancher{\\*[2pt] \hline}
\begin{tabular}{|c|c|c|c|c|}
\cline{1-2}
\multicolumn{2}{ |l| }{\textbf{\Tr{Continuous distributions}{Kontinuerliga fördelningar}}:} \cr
\hline
\EspaceAuDessus     \Tr{$X$ from}{$X$ från}
                  & $f(x)$
                  & \Tr{$F(x)=P(X\le x)$}{$F(x)=P(X\le x)$}
                  & \Tr{$\mu=E(X)$}{$\mu=E(X)$}
                  & \Tr{$\sigma=\sqrt{\Var(X)}$}{$\sigma=\sqrt{V(X)}$}
                  \duPlancher
\hline
  \EspaceAuDessus $\mbox{Unif}(a,b)$  &
                  $ \frac{1}{b-a},\; a\le\! x\le\! b $ &
                  $\frac{x-a}{b-a},\; a\le\! x\le\! b $ &
                  $\frac{a+b}{2}$ &
                  $\frac{b-a}{2\sqrt{3}}$
                  \cr &&&&\\[-23pt]
                  \duPlancher
  \EspaceAuDessus $\mbox{Exp}(\lambda)$  &
                  $\lambda e^{-\lambda x}$,\, $x\ge0$ &
                  $1-e^{-\lambda x}$ &
                  $1/\lambda$ & $1/\lambda$\duPlancher
  \EspaceAuDessus $N(\mu,\sigma) $ &
                  %% $\frac{1}{\sigma\sqrt{2\pi}}\,e^{-(x-\mu)^2/2\sigma^2}$ &
                  $\frac{1}{\sigma\sqrt{2\pi}}\,e^{-(\frac{x-\mu}\sigma)^2/2}$ &
                  $\Phi\Bigl(\frac{x-\mu}{\sigma}\Bigr)
                  =\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\frac{x-\mu}{\sigma}} e^{-t^2/2}\,dt$ &
                  $\mu$ & $\sigma$\\*[10pt]\hline
\end{tabular}

\medskip
\begin{tabular}{|c|c|c|c|c|}
\cline{1-2}
\multicolumn{2}{ |l| }{\textbf{\Tr{Discrete distributions}{Diskreta fördelningar}} ($x=0,1,2,\ldots$):} \cr
\hline
\EspaceAuDessus     \Tr{$X$ from}{$X$ från}
                  & $f(x)=P(X=x)$
                  & \Tr{$F(x)=P(X\le x)$}{$F(x)=P(X\le x)$}
                  & \Tr{$\mu=E(X)$}{$\mu=E(X)$}
                  & \Tr{$\sigma=\sqrt{\Var(X)}$}{$\sigma=\sqrt{V(X)}$}
                  \duPlancher
\hline
\EspaceAuDessus $\mbox{Unif}\{1,n\}$  &
                  $ \frac{1}{n},\; 1\le\! x\le\! n $ &
                  $ \frac{x}{n},\; 1\le\! x\le\! n $ &
                  $\frac{n+1}{2}$ &
                  $\frac{\sqrt{n^2-1}}{2\sqrt{3}}$
                  \cr &&&&\\[-23pt]
                  \duPlancher
  \EspaceAuDessus $\mbox{Geo}(p)$,\, $x\ge1$ &
                  $p(1-p)^{x-1}$ &
                  $1 - (1-p)^x$ &
                  $1/p$ & $\sqrt{1-p}\big/p$\duPlancher
  \EspaceAuDessus $\mbox{Hyp}(N,n,p)$ &
                  $\frac{\binom{Np}x\binom{N(1-p)}{n-x}}{\binom{N}{n}}$ &
                  $\sum_{k=0}^x\frac{\binom{Np}k\binom{N(1-p)}{n-k}}{\binom{N}{n}}$ &
                  $np$ & $\sqrt{\tfrac{N-n}{N-1}\,np(1-p)}$\duPlancher
  \EspaceAuDessus $\mbox{Bin}\,(n,p)$    &
                  $\binom nx p^x(1-p)^{n-x}$ &
                  $\sum_{k=0}^x\binom nk p^k(1-p)^{n-k}$ &
                  $np$ & $\sqrt{np(1-p)}$\duPlancher
  \EspaceAuDessus $\Po(\mu) $ &
                  $e^{-\mu}\,\frac{\mu^x}{x!}$ &
                  $e^{-\mu}\,\sum_{k=0}^x \frac{\mu^k}{k!}$ &
                  $\mu$ & $\sqrt{\mu}$\duPlancher
\end{tabular}
%>>>

\subsection*{\Tr{Linear combinations, sums and averages of random variables}%<<<
             {Linjära kombinationer, summor och snitt av stokastiska variabler}
         }
\Tr{%
Suppose that $\{X_k\}_{k=1}^n$ are (discrete or continuous) random variables with expectations
$E(X_k)=\mu_k$ and variances $\Var(X_k)=\sigma_k^2$, $k=1,...,n$, and let
 $\{a_k\}_{k=1}^n$ be constants. Then
}{%
Antag att $\{X_k\}_{k=1}^n$ är (diskreta eller kontinuerliga) stokastiska variabler med
väntevärden $E(X_k)=\mu_k$ och varianser $V(X_k)=\sigma_k^2$, $k=1,...,n$, samt
 $\{a_k\}_{k=1}^n$ är konstanter. Då gäller
}
\[
\Tr{
\eqalign{
E(a_1X_1+\cdots+a_nX_n)& =a_1\mu_1+\cdots + a_n\mu_n\cr
\Var(a_1X_1+\cdots+a_nX_n)& =a_1^2\sigma_1^2+\cdots + a_n^2\sigma_n^2
   \quad(\mbox{if $X_1,\ldots,X_n$ are independent}).
} % eqalign
}{
\eqalign{
   E(a_1X_1+\cdots+a_nX_n)& =a_1\mu_1+\cdots + a_n\mu_n\cr
V(a_1X_1+\cdots+a_nX_n)& =a_1^2\sigma_1^2+\cdots + a_n^2\sigma_n^2
   \quad(\mbox{om $X_1,\ldots,X_n$ är oberoende}).
} % eqalign
}
\]
\Tr{%
If $\{X_k\}_{k=1}^n$ are \textbf{normal and independent} r.\,v.,
then their linear combinations also are normally distributed:
}{%
Om $\{X_k\}_{k=1}^n$ är \textbf{normalfördelade och oberoende},
så är deras linjärkombinationer också normalfördelade:
}
\[
\Tr{X}{X}_k\Tr{\sim}{\sim} N(\mu_k,\sigma_k),\;
k=1,...,n
\;\Rightarrow\;
a_1\Tr{X}{X}_1+\cdots+a_n\Tr{X}{X}_n\Tr{\sim}{\sim} N\bigl(a_1\mu_1+\cdots a_n\mu_n,
                   \sqrt{a_1^2\sigma_1^2+\cdots a_n^2\sigma_n^2}\,\bigr).
\]
\Tr{%
For \textbf{sums} and \textbf{averages of i.i.d.~normal} variables, in particular, holds:
}{%
I synnerhet, för \textbf{summor} och \textbf{snitt av lika normalfördelade oberoende} variabler gäller:
}
$$
\Tr{X}{X}_k\Tr{\sim}{\sim} N(\mu,\sigma),\;
k=1,...,n
\;\Rightarrow\;
\cases{
X = \Tr{X}{X}_1+\cdots+\Tr{X}{X}_n \Tr{\sim}{\sim} N(n\mu,\sigma\sqrt{n})
\Leftrightarrow
Z=\frac{X-n\mu}{\sigma\sqrt{n}}\Tr{\sim}{\sim} N(0,1)
\cr\noalign{\vskip5pt}
\overline{X}
=\frac{\Tr{X}{X}_1+\cdots+\Tr{X}{X}_n}{n} \sim N(\mu,\frac{\sigma}{\sqrt{n}})
\hspace{8pt}\Leftrightarrow
Z=\frac{\Tr{\ob X}{\ob X} -\mu}{\sigma/\sqrt{n}}\Tr{\sim}{\sim} N(0,1)
}
$$

\medskip\textbf{\Tr{A Poisson process of intensity}{Poissonprocess med intensitet}} $\lambda$: %<<<
\Tr{A point process where times between consecutive points are i.i.d.~random variables that are $\Exp(\lambda)$}
   {Fullständig slumpmässig följd av händelser med tider mellan händelserna som är $\Exp(\lambda)$}:
%%% \begin{center}
%%%   \fbox{
%%% \Tr{If}{om} \/
%%% $
%%%      \Bigl\{\mkern-6mu
%%%      \begin{array}{l}
%%%        X_k  \sim\Po(\lambda t_k)\\
%%%        k=1,2,\ldots,n
%%%      \end{array}
%%%    \mkern-6mu\Bigr\} \/
%%%    $
%%%    \Tr{then}{då}
%%%    $
%%%      X = X_1+X_2+\cdots + X_n \sim \Po(\mu),\; \mu=\lambda(t_1+\cdots+t_n)
%%%    $
%%%   }
%%% \end{center}
\[
 % \mbox{\Tr{If}{Om} }\;
  \Bigl\{\mkern-6mu
  \begin{array}{l}
    X_k  \sim\Po(\lambda t_k)\\
    k=1,2,\ldots,n
  \end{array}
\mkern-6mu\Bigr\}
% \;\mbox{ \Tr{then}{då} }\;
\Rightarrow
  X = X_1+X_2+\cdots + X_n \sim \Po(\mu),\; \mu=\lambda(t_1+\cdots+t_n)
\]%>>>
%>>>

\subsection*{\Tr{The Central Limit Theorem (CLT)}{Centrala gränsvärdessatsen (CGS)}} %<<<

\Tr{%
Let $X_1,\cdots, X_n$ be \textbf{independent identically distributed}  (i.i.d.)
random variables with expectation $\mu$ and standard deviation $\sigma$. Then for large $n$
holds:
}{%
Låt $X_1,\cdots, X_n$ vara \textbf{oberoende likafördelade} stokastiska
variabler med väntevärde $\mu$ och standardavvikelse $\sigma$. För stora $n$
gäller:
}

\begin{itemize}
  \item $X=\sum_{k=1}^n \Tr{X}{X}_k=\Tr{X}{X}_1+\cdots+\Tr{X}{X}_n\;
    \stackrel{\mbox{\tiny appr}}{\sim}\; N(n\mu,\sigma\sqrt{n})$,
        \ \Tr{i.e.}{dvs}, \,
        $P(X\le x)\approx
        \Phi(z),\, z=\frac{x-n\mu}{\sigma\sqrt{n}}
        $

      \item $\Tr{\ob X}{\ob X}=\frac{X}n
    =\frac{\Tr{X}{X}_1+\cdots+\Tr{X}{X}_n}n\;
    \stackrel{\mbox{\tiny appr}}{\sim}\; N(\mu,\frac\sigma{\sqrt{n}})$,
    \hspace{26pt}\Tr{i.e.}{dvs}, \,
        $P(\Tr{\ob X}{\ob X}\le \ob x)\approx\Phi(z)$, \,
        $z=\frac{\ob x-\mu}{\sigma/\sqrt{n}}$
\end{itemize}
%>>>

% Chebyshev + LBN <<<
\[
  \begin{array}[m]{|c|c|}
    \hline
    \mbox{\textbf{\Tr{The Chebyshev inequality}{Tjebyshevs olikhet}}}
    &
    \mbox{\textbf{\Tr{The Law of Big Numbers}{De stora talens lag}} }
    \rule{0pt}{13pt}
    (\{X_k\}_1^n - \mbox{ i.i.d.},\; E(X_k)=\mu,\; \Var(X_k)=\sigma^2)\mkern-5mu:
    \\[3pt]\hline
    \rule[-10pt]{0pt}{27pt}
  P(|X-\mu_X|\ge a) \le\frac{\sigma_X^2}{a^2}, \; a>0
  &
  \lim_{n\to\infty}P(|\overline X-\mu|\ge\varepsilon)
  = \lim_{n\to\infty}\frac{\sigma^2}{n\varepsilon^2}=0, \; \varepsilon>0
  \\ \hline
  \end{array}
\] %>>>

\subsection*{\Tr{Approximations of distributions}{Approximationer}}%<<<
\medskip
\begin{center}
   \includegraphics[scale=0.65]{Figs/approx}
\end{center}
%>>>

\subsection*{\Tr{Statistical inference}{Statistisk inferens}}%<<<

\subsubsection*{\Tr{Point estimators}{Punktskattningar}}

\Tr{%
\textbf{One sample}:
Let $x_1,\dots,x_n$ be the observed values of a sample $\left\{X_k\right\}_1^n$ from a population with
mean $\mu$ och standard deviation $\sigma$. Point estimators
for the mean and the variance of the population are
}{%
\textbf{En stickprov}:
Låt $x_1,\dots,x_n$ vara de observerade värden för ett stickprov
$\left\{X_k\right\}_1^n$ från en population med
väntevärde $\mu$ och standardavvikelse $\sigma.$ Väntevärdesriktiga skattningar
av $\mu$ och $\sigma^2$ är då
}

\[
  \begin{array}[m]{|l|l|}
  \hline
  \overline{x}=\hat\mu_\obs=\frac{1}{n}\sum_{i=1}^n x_i
  &
     s^2
     =\widehat{\sigma^2}_\obs
     =\frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})^2
     =\frac{1}{n-1}\Bigl(\sum_{i=1}^nx_i^2-n\overline{x}^2\Bigr)
     %\; \mu~\mbox{\Tr{not known}{ej känd}}
  \cr\hline
  \end{array}
\]

\textbf{\Tr{Two samples}{Två stickprov}},
$\{X_k\}_1^n$ \Tr{and}{och} $\{Y_k\}_1^n$
\Tr{with observations}{med observationer}
$\{x_k\}_1^n$ \Tr{and}{och} $\{y_k\}_1^n$,
\Tr{point estimator for the covariance}{skattning för kovariancen}:
\[
  \begin{array}[m]{|l|l|}
  \hline
  s_{xy} = \widehat{\Cov(X,Y)}_{\obs}
     =\frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})
     =\frac{1}{n-1}\Bigl(\sum_{i=1}^nx_iy_i-n\bar{x}\bar{y}\Bigr)
   & 
     %\mbox{\Tr{in particular}{i synnerhet}}, \;
     \Bigl\{\mkern-6mu
       \begin{array}[m]{rcl} \rule{0pt}{14pt}
       s_{xx} &=& s_x^2 = (\widehat{\sigma^2_X})_\obs\\[2pt]
       s_{yy} &=& s_y^2 = (\widehat{\sigma^2_Y})_\obs\\[2pt]
     \end{array}
  \cr\hline
\end{array}
\]

\textbf{\Tr{Correlation coefficient}{Korrelationskoefficient}}:
\fbox{$
  r =  \frac{s_{xy}}{s_xs_y}
    =  \frac{s_{xy}}
            { \sqrt{s_{xx}s_{yy}} }
$}
\hfil
\textbf{\Tr{Linear regression}{Linjär regression}}:
\fbox{$
  \hat y = a + bx, \;
  \Bigl\{\mkern-6mu
  \begin{array}[m]{l}
  b =  s_{xy}/s_{xx} \cr
  a = \bar y - b\bar x
  \end{array}
$}

%>>>

\subsubsection*{\Tr{Confidence Interval -- One Sample}{Konfidensintervall - ett stickprov}}%<<<

\begin{eqnarray*}\begin{array}{|c|c|c|}\hline
     \mbox{\Tr{Estimated paramter $\theta$}{Parameter $\theta$ som skattas}}
   & \mbox{\Tr{Point estimate}{Punktskattning}}
   & \mbox{\Tr{Two-tailed}{Tvåsidigt konfidensintervall} }
   \CI_{1-\alpha}(\theta) \\

\hline && \\
\mu \;\mbox{\Tr{from}{från} } N(\mu,\sigma),\; \sigma \mbox{ \Tr{known}{känd}}
 & \overline{x}
 &  \ob x \pm \Tr{z}{\lambda}_{\alpha/2}\frac{\sigma}{\sqrt{n}}\\&&\\

\hline &&\\
\mu \;\mbox{\Tr{from}{från} } N(\mu,\sigma),\; \sigma \mbox{ \Tr{not known}{ej känd}}
 & \overline{x}
& \ob x \pm t_{\alpha/2,n-1}\frac{s}{\sqrt{n}}\\&&\\

\hline &&\\p \;\mbox{ \Tr{from}{från} Bin}(n,p) & \frac xn
& \hat p_\obs\pm
\Tr{z}{\lambda}_{\alpha/2}\sqrt{\frac{\hat p_\obs(1-\hat p_\obs)}{n}}

\\&&\\

\hline &&\\
\sigma^2 \;\mbox{\Tr{from}{från} } N(\mu,\sigma)
 & s^2&\frac{(n-1)s^2}{\chi^2_{\alpha/2,n-1}}
  \leq\sigma^2
  \leq \frac{(n-1)s^2}{\chi^2_{1-\alpha/2,n-1}}

 \\&&\\
\hline

  \end{array}
\end{eqnarray*}
%>>>

\subsubsection*{\Tr{Confidence Interval for the Mean -- Two Samples}%<<<
                   {Konfidensintervall -- två normalfördelade stickprov}}

\begin{itemize}

\item \textbf{\Tr{Two samples (paired data)}{Två parade stickprov}}: %<<<
  $\{(X_i,Y_i)\}_{i=1}^n$
  \Tr{with}{där}
   $X_i\Tr{\sim}{\sim} N(\mu_i,\sigma_x)$ \Tr{and}{och}
   $Y_i\Tr{\sim}{\sim} N(\mu_i+\Delta,\sigma_y)$, $i=1,\dots,n$.
   \Tr{Then}{Då} $\{Z_i\}_1^n=\{Y_i-X_i\}_1^n$
   \Tr{is a sample from}{är ett stickprov från}
   $N(\Delta,\sigma_z)$.
   \Tr{The two-sided $\CI_{1-\alpha}$ for}{Det tvåsidiga $\CI_{1-\alpha}$ för} $\Delta$:

\[
\CI_{1-\alpha}(\Delta)
   = \ob z
     \pm
   \cases{
      \Tr{z}{\lambda}_{\alpha/2}\,\frac{\sigma_z}{\sqrt{n}}\;,
          & \Tr{if}{om} $\sigma_z$ \Tr{is known}{är känd} \cr
      t_{\alpha/2,n-1}\,\frac{s_z}{\sqrt{n}}\;,
      & \Tr{if}{om} $\sigma_z$ \Tr{is not known}{är ej känd} \cr
   }
\]%>>>

\item \textbf{\Tr{Two independent samples (pooled test)}{Två oberoende stickprov}}:
$\{X_i\}_{i=1}^{n}$ \Tr{from}{från} $N(\mu_x,\sigma)$
  \Tr{and}{och}
  $\{Y_i\}_{i=1}^{m}$ \Tr{from}{från} $N(\mu_y,\sigma)$.
  \Tr{The two-tailed $\CI_{1-\alpha}$ for $\mu_x-\mu_y$ is given by}
      {Det tvåsidiga $\CI_{1-\alpha}$ för $\mu_x-\mu_y$ ges av}
\[
  \CI_{1-\alpha}(\mu_x-\mu_y)
  = (\ob x-\ob y)
    \pm
   \cases{
   \Tr{z}{\lambda}_{\alpha/2}\,\sigma\sqrt{\frac1n+\frac1m},
          & \Tr{if}{om} $\sigma$ \Tr{is known}{är känd} \cr
          t_{\alpha/2,n+m-2}\,s_p\sqrt{\frac1n+\frac1m}\,,
      & \Tr{if}{om} $\sigma$ \Tr{is not known}{är ej känd}, \cr
   }
\]
\Tr{where}{där}
$s_p$
\Tr{is the pooled (weighted) standard deviation}{är den vägda (pooled) standardavvikelsen}
\/$s_p =\sqrt{\frac{(n-1)s_x^2+(m-1)s_y^2}{n+m-2}}\,\cdot$

\end{itemize}
%>>>

\subsection*{\Tr{Hypothesis tests}{Hypotestest}}%<<<

\subsubsection*{ \Tr{Parametric methods}{Parametriska metoder}}%<<<

\begin{eqnarray*}\begin{array}{|cccc|}
  \hline
   \mbox{\Tr{Null hypothesis}{Nollhypotes}} &
   \mbox{\Tr{Test variable}{Testvariabel}} &
   \mbox{\Tr{Alt.~hypothesis}{Mothypotes}}  &
   \mbox{\Tr{$H_0$ rejected if}{När $H_0$ förkastas}}
  \\ \hline &&&\\[-10pt]
  &&H_1:\mu\neq\mu_0&\vert z_0\vert>\Tr{z}{\lambda}_{\alpha/2} \\
    H_0:\mu=\mu_0
   &z_0=\frac{\overline{x}-\mu_0}{\sigma/\sqrt{n}}
   &H_1:\mu>\mu_0&z_0>\Tr{z}{\lambda}_\alpha\\
   \sigma \mbox{ \Tr{known}{känd}}
  &&H_1:\mu<\mu_0&z_0<-\Tr{z}{\lambda}_\alpha
  \\ \hline &&&\\[-10pt]
  &&H_1:\mu\neq\mu_0&\vert t_0\vert>t_{\alpha/2,n-1} \\
    H_0:\mu=\mu_0 & t_0=\frac{\overline{x}-\mu_0}{s/\sqrt{n}}
   &H_1:\mu>\mu_0 & t_0>t_{\alpha,n-1}  \\
   \sigma \mbox{ \Tr{not known}{ej känd}}
  &&H_1:\mu<\mu_0 & t_0<-t_{\alpha,n-1}
\\ \hline &&&\\[-10pt]
  &&H_1:\sigma^2\neq\sigma^2_0
    % & \chi^2_0<\chi^2_{1-\alpha/2,n-1} \mbox{\, \Tr{or}{eller} \,\,} \chi^2_0>\chi^2_{\alpha/2,n-1}
    & \chi^2_0 \notin [\chi^2_{1-\alpha/2,n-1} \,,\, \chi^2_{\alpha/2,n-1}]
     \\
 H_0:\sigma^2=\sigma^2_0
    &\chi^2_0=\frac{(n-1)s^2}{\sigma^2_0}
    &H_1:\sigma^2>\sigma^2_0
    &\chi^2_0>\chi^2_{\alpha,n-1}  \\
&&H_1:\sigma^2<\sigma^2_0&\chi^2_0<\chi^2_{1-\alpha,n-1}
\\ \hline &&&\\[-10pt]
  &&H_1:p\neq p_0&\vert z_0\vert>\Tr{z}{\lambda}_{\alpha/2}\\
   H_0:p=p_0
   &z_0=\frac{x-np_0}{\sqrt{np_0(1-p_0)}}
   &H_1:p>p_0&z_0>\Tr{z}{\lambda}_\alpha \\
  &&H_1:p<p_0&z_0<-\Tr{z}{\lambda}_\alpha
\\ \hline \end{array}
\end{eqnarray*}
%>>>

\subsubsection*{\Tr{Non-parametric methods}{Icke-parametriska metoder}}%<<<

\vspace{-5pt}
\begin{center}
%%%%% \begin{tabular}[t]{|c|*{4}{>{$}c<{$}}|}
%%%%%   \cline{2-5}\multicolumn{1}{c|}{}
%%%%%    &
%%%%%    \mbox{\Tr{Null hypothesis}{Nollhypotes}} &
%%%%%    \mbox{\Tr{Alt.~hypothesis}{Mothypotes}}  &
%%%%%    \mbox{\Tr{Test variable}{Testvariabel}} &
%%%%%    \mbox{\Tr{$H_0$ rejected if}{När $H_0$ förkastas}}
%%%%%    \\ \hline
%%%%%      &&H_1:{\md}\neq{\md}_0&r=\min(r^-,r^+)&r\leq r_{\alpha/2} \\
%%%%%      \mbox{\textbf{\Tr{Sign test}{Teckentest}}}
%%%%%       &H_0:{\md}={\md}_0&H_1:{\md}>{\md}_0&r^-&r^-\leq r_\alpha \\
%%%%%      \mbox{\Tr{for the median}{för medianen}}
%%%%%      &&H_1:{\md}<{\md}_0&r^+&r^+\leq r_\alpha
%%%%%  \\\hline
%%%%% \end{tabular}

\begin{tabular}[t]{|c|*{3}{>{$}c<{$}}|}
  \cline{2-4}\multicolumn{1}{c|}{}
   &
   \mbox{\Tr{Null hypothesis}{Nollhypotes}} &
   \mbox{\Tr{Alt.~hypothesis}{Mothypotes}}  &
   \mbox{\Tr{$H_0$ rejected if}{När $H_0$ förkastas}}
   \\ \hline
   \mbox{\textbf{Wilcoxon\Tr{'}{}s}}
 %%% Fredrik's old %<<<
 %%%           &&H_A:\mu_A\neq\mu_B&w=\min(w_A,w_B)&w\leq w^*_\alpha\\
 %%% \mbox{\Tr{Rang Sum Test}{Rangsummatest}}
 %%%            &H_0:\mu_A=\mu_B&H_A:\mu_A>\mu_B&w_B&w_B\leq w^*_\alpha \\
 %%% \mbox{\Tr{Requires}{Krav}: }n_A\leq n_B
 %%%           &&H_A:\mu_A<\mu_B&w_A&w_A\leq w^*_\alpha \\\hline
 %%% %>>>
            &&H_1:\mu_A\neq\mu_B
            &(w_A \leq w^-_{\alpha/2}) \mbox{ or }
             (w_A \geq w^+_{\alpha/2})
             \cr
\textbf{\Tr{Rank Sum Test}{Rangsummatest}}
             &H_0:\mu_A=\mu_B&H_1:\mu_A>\mu_B&w_A\geq w^+_\alpha \\
  \Tr{Requires}{Krav}: $n_A\leq n_B$
            &&H_1:\mu_A<\mu_B&w_A\leq w^-_\alpha \\\hline
\end{tabular}
\end{center}
%>>>

\subsubsection*{Test statistic for the $\chi^2$-tests:}%<<<

\vspace{-5pt}
\hfil
\begin{tabular}[t]{|c|c|}
  \hline
  \textbf{Goodness-of-fit}:
     $\chi^2 = \sum_{i=1}^{n}\frac{(O_i-E_i)^2}{E_i}$ &
     \parbox[m]{12em}{
     \textbf{Test for independence}: \\
    ($m\times n$-contingency table)
     }
  $\chi^2 = \sum_{i=1}^m\sum_{j=1}^{n}\frac{(O_{ij}-E_{ij})^2}{E_{ij}}$ \cr
  \hline
\end{tabular}
%>>>

%>>>

\label{LastPageNo}
\end{document}

>> THROWNAWAY SECTION:

\section*{Joint distributions}%<<<

\begin{itemize}

  \item \textbf{Joint density, discrete case}: %<<<
$
f_{XY}(x,y) = P[(X = x)\cap(Y = y)],
\quad
\cases{
  f_{XY}(x,y)\ge 0
  \cr
  \sum_x
  \sum_y
  f_{XY}(x,y) = 1.
}
$%>>>

  \item \textbf{The joint density in the continuous case} is a function $f_{X,Y}(x,y)\ge 0$ which satisfies: %<<<
\[
P[(a\le X\le b)\cap(c\le Y\le d)] =
 \int\limits_a^b\mkern-10mu\int\limits_c^d f_{XY}(x,y) \,dxdy,
\qquad
\iint_{\mkern-12mu\Rone^2} f_{XY}\,dxdy = 1.
\]

  \item \textbf{Cumulative distribution function} (discrete and continuous):
  $F_{XY}(x,y)=P[(X\le x)\cap(Y\le y)]$.%>>>

  \item \textbf{Marginal densities}: %<<<
    \[
      F_X(x) = \cases{
      \sum_y f_{XY}(x,y) &, discrete case
         \cr
         \int_{-\infty}^\infty f_{XY}(x,y)\,dy &, continuous case
      }
      \quad
      F_Y(y) = \cases{
      \sum_x f_{XY}(x,y) &, discrete case
         \cr
      \int_{-\infty}^\infty f_{XY}(x,y)\,dx &, continuous case.
      }
    \]%>>>

  \item Variables $X$ and $Y$ are \textbf{independent} if: %<<<
  $f_{XY}(x,y)=f_X(x)f_Y(y)$.%>>>

  \item \textbf{Expectations}:%<<<
    \[
\eqalign{
\mu_x
 & = E(X) = \cases{
    \sum_x\sum_y xf_{XY}(x,y) = \sum_x xf_X(x) &, discrete case \cr
    \iint_{\mkern-12mu\Rone^2}xf_{XY}(x,y)\,dxdy = \int_{-\infty}^\infty xf_{X}(x)\,dx &, continuous case
    }
\cr
\mu_y
  & = E(Y) = \cases{
    \sum_x\sum_y yf_{XY}(x,y) =\sum_y yf_X(y) &, discrete case \cr
    \iint_{\mkern-12mu\Rone^2}yf_{XY}(x,y)\,dxdy = \int_{-\infty}^\infty yf_{Y}(y)\,dy &, continuous case.
    }
   }
\]%>>>

  \item \textbf{Covariance}: %<<<
  \[
  \Cov(X,Y) = E[(X-\mu_x)(Y-\mu_y)]= E(XY)-\mu_x\mu_y .
%%  \mbox{ In particular, }\Var(X)=\Cov(X,X).
  \] %>>>

  \item \textbf{Pearson coefficient of correlation}:%<<<
  \[
  \rho_{XY} = \frac{\Cov(X,Y)}{\sigma_X\sigma_Y}
       = \frac{\Cov(X,Y)}{\sqrt{\Cov(X,X)\Cov(Y,Y)}}\, ,
       \quad
       -1\le\rho\le 1.
  \]%>>>

\item If the random variables $X$ and $Y$ are \textbf{independent}
    $\Rightarrow$ $\rho_{XY}=0$ ($X$ and $Y$ are
    \textbf{uncorrelated}). The converse is not true in general.

\end{itemize} %>>>
